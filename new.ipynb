{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>  Build agentic AI application using Langgraph </h1>\n",
    "<p> Built by Jakob Lindstr√∏m, aka DataJakob@Github,  for Lumos  SDC. </p>\n",
    "<p> In this notebook  we will create a agentic chatbot that is especially good at Q&A for finance and portfolio generation </p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 1 Import libraries </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enviroment \n",
    "import os\n",
    "\n",
    "# Classes packages\n",
    "from typing import Annotated\n",
    "from typing import TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# \"Lang\" packages\n",
    "import langchain\n",
    "import langgraph\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# Other\n",
    "from demo.analyze.data import PortofolioCloud\n",
    "from demo.analyze.optimizer import Optimized\n",
    "\n",
    "# .env variables\n",
    "# my_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 2 State and classes </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    mission: str\n",
    "    stocks: Annotated[list, add_messages]\n",
    "\n",
    "class Mission(BaseModel):\n",
    "    mission: str = Field(description=\"\"\"\n",
    "                         Answer with one word based on the user query:\n",
    "                         - \"append\", if the user wants to append  the stock into the portfolio.\n",
    "                         - \"info\"  if the user wants more info about a stock or something else.\n",
    "                         - \"analyze\"  if  the user wants to analyze the current portfolio,\n",
    "                         - \"other\", if nothing of the above is specified.\n",
    "                        \"\"\")\n",
    "    \n",
    "class Filter(BaseModel):\n",
    "    company: str = Field(description=\"\"\"\n",
    "                         Identify the Norwegian public listed company.\n",
    "                         \"\"\")\n",
    "    ticker: str = Field(description=\"\"\"\n",
    "                        Identify the financial ticker of the mentioned company. \n",
    "                        \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 3 Model and Nodes </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    temperature=0,\n",
    "    api_key=my_api_key\n",
    ")\n",
    "\n",
    "\n",
    "def chatbot(system_message, user_message):\n",
    "    \"\"\"\n",
    "    A general chatbot function that takes in a custom system and user message.\n",
    "    \"\"\"\n",
    "    system_input = \"You are chatbot specializing in financial advisory. \" + str(system_message)\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_input),\n",
    "    ])\n",
    "    info_model = prompt | llm \n",
    "    response =  info_model.invoke({\"user\":user_message})\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def navigator(state: State):\n",
    "    \"\"\"\n",
    "    Function that identify the intention of the user\n",
    "    \"\"\"\n",
    "    nav_model =  llm.with_structured_output(Mission)\n",
    "    response = nav_model.invoke(state[\"messages\"]).mission\n",
    "    return {\"mission\": response}\n",
    "\n",
    "\n",
    "\n",
    "def info(state: State):\n",
    "    \"\"\"\n",
    "    Function that returns information about a public lsited company\n",
    "    \"\"\"\n",
    "    nav_model =  llm.with_structured_output(Filter)\n",
    "    company = nav_model.invoke(state[\"messages\"]).company\n",
    "    response = chatbot(\"\"\"Be brief and concise and present\"\"\" + company +\"\"\" and its main operations.\"\"\",\n",
    "                        state[\"messages\"]\n",
    "                        )\n",
    "    print(state[\"messages\"])\n",
    "    print(\"leave here\")\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "    \n",
    "def stock_appender(state: State):\n",
    "    \"\"\"\n",
    "    Function that filters down the user input and identify a ticker and adds it to a list\n",
    "    \"\"\"\n",
    "    nav_model =  llm.with_structured_output(Filter)\n",
    "    ticker = nav_model.invoke(state[\"messages\"]).ticker+\".OL\"\n",
    "    response = chatbot(\"\"\"You have just added a stock to a portfolio, ask the user if a new stock should be added.\n",
    "                        Or if the user wants to get info about a company or  analyze the portfolio\"\"\",\n",
    "                        state[\"messages\"]\n",
    "                        )\n",
    "    return {\"messages\": response,\n",
    "            \"stocks\":ticker}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def portfolio_analyzer(state: State):\n",
    "    \"\"\"\n",
    "    Function that takes in a portfolio generated through chat \n",
    "    and analyzes the optimal posistions according to the Sharpe ratio.\n",
    "    \"\"\"\n",
    "    stocks = [x.content for x in state[\"stocks\"]]\n",
    "    alfa = PortofolioCloud(stocks)\n",
    "    alfa.final_df()\n",
    "    bravo = Optimized(alfa.stocks, alfa.df,\n",
    "                    alfa.tot_cov_mat,alfa.neg_cov_mat,\n",
    "                    alfa.returns, alfa.mean, alfa.std)\n",
    "    bravo.PortofolioOptimizer()\n",
    "    positions =  bravo.optimized_portofolios\n",
    "    myStr = \"\"\n",
    "    for i in range(0, len(stocks),1):\n",
    "        myStr += str(stocks[i]+ \" at \" +str(round(positions[2][0][i]*100,1))+\"%, \")\n",
    "    response = chatbot(\"\"\"Use this input from the user to inform the user about the stock posistion that would generate\n",
    "                           the best portfolio based on the Sharpe ratio. Be brief and concise\"\"\"+myStr,\n",
    "                            state[\"messages\"]\n",
    "                            )\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "\n",
    "def other(state: State):\n",
    "    \"\"\"\n",
    "    Function that forces the user to give \"valid\" input to the graph\n",
    "    \"\"\"\n",
    "    response = chatbot(\"\"\"The user has given you a unrelated query, make the user give queries about appending stocks to a porfolio,\n",
    "                        get information about a company or analyze a portfolio \"\"\",\n",
    "                        state[\"messages\"]\n",
    "                        )\n",
    "    return {\"messages\": response}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 4 Edges</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision(state: State):\n",
    "    \"\"\"\n",
    "    Function that takes the output from the nav node and decides what would be the next node.\n",
    "    \"\"\"\n",
    "    if state[\"mission\"] == \"append\":\n",
    "        return \"append\"\n",
    "    elif state[\"mission\"] == \"analyze\":\n",
    "        return  \"analyze\"\n",
    "    elif state[\"mission\"] == \"info\":\n",
    "        return \"info\"\n",
    "    else:\n",
    "        return \"other\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 5 Workflow Compilation </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the graph and create a memory saver\n",
    "workflow = StateGraph(State)\n",
    "memory = MemorySaver()\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"nav\", navigator)\n",
    "workflow.add_node(\"info\", info)\n",
    "workflow.add_node(\"append\", stock_appender)\n",
    "workflow.add_node(\"analyze\", portfolio_analyzer)\n",
    "workflow.add_node(\"other\", other)\n",
    "\n",
    "# Add edges\n",
    "workflow.add_edge(START, \"nav\")     # Non-optional move\n",
    "workflow.add_conditional_edges(\"nav\",   # Starting node\n",
    "                               decision,    # Decider for which node to go to\n",
    "                               # Options\n",
    "                               {\"info\":\"info\",\n",
    "                                \"append\":\"append\",\n",
    "                                \"analyze\":\"analyze\",\n",
    "                                \"other\":\"other\"}\n",
    "\n",
    ")\n",
    "workflow.add_edge(\"info\", END)\n",
    "workflow.add_edge(\"append\", END)\n",
    "workflow.add_edge(\"analyze\", END)\n",
    "workflow.add_edge(\"other\", END)\n",
    "\n",
    "# Compile and save the graph\n",
    "mygraph = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 6 Start chatting :) </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_graph_updates(user_input: str):\n",
    "    for event in mygraph.stream({\"messages\": [(\"user\", user_input)]},\n",
    "                                {\"configurable\": {\"thread_id\": \"0g\"}}):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value)\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        print(user_input)\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        # fallback if input() is not available\n",
    "        user_input = \"----Something wong here------\"    \n",
    "        print(\"User: \" + user_input)\n",
    "        stream_graph_updates(user_input)\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvLSDC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
