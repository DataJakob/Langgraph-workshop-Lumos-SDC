{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Try it yourself notebook: The Query Refiner </h1>\n",
    "<p> In this notebook you will go through all the steps of making a simple agentic AI application using Langgraph. This notebook isn't complete and requires YOU to write some code. </p>\n",
    "<p> This AI system has the intention of retrieving a messy (bad formulated) user query, transform it into a well-formulated one and finally, answer it. </p>\n",
    "<h2> 1 Import packages and load enviroment variables </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enviroment \n",
    "import os\n",
    "\n",
    "# Classes packages\n",
    "from typing import Annotated\n",
    "from typing import TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# \"Lang\" packages\n",
    "import langchain\n",
    "import langgraph\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# .env variables\n",
    "# my_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 2 State </h1>\n",
    "<p> The class State is the state of the system. You can look at it as the memory of what the chatbot-system remebers.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    refined_q: str = Field(description=\"A refined version of the latest user query.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 3 Nodes </h2>\n",
    "<p> In this task you shall do the following: \n",
    "    <ol>\n",
    "        <li> Come up with a system prompt that transform a messy user query into a well defined question. </li>\n",
    "        <li>Determine which variable that shall be sent into the state of the system</li>\n",
    "        <li>Create a prompt template and a chain.</li>\n",
    "    </ol>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    temperature=0,\n",
    "    api_key=my_api_key\n",
    ")\n",
    "\n",
    "\n",
    "def refine_node(state: State):\n",
    "    # Fill in the blank\n",
    "    system_prompt = None\n",
    "    prompt = ChatPromptTemplate.form_messages([\n",
    "        (\"system\", system_prompt)\n",
    "    ])\n",
    "    chain = prompt | llm\n",
    "    response = chain.invoke({\"user\": state[\"messages\"]}).content\n",
    "    # Fill in the blank\n",
    "    return {\"refined_question\": None}\n",
    "\n",
    "\n",
    "def answer_node(state:State):\n",
    "    system_prompt = \"\"\"\n",
    "                    Answer the following user question. Be brief, but concise!\n",
    "                    \"\"\"\n",
    "    # Fill in the blanks\n",
    "    prompt = None\n",
    "    chain = None\n",
    "    response = chain.invoke({\"user\": state[\"messages\"]}).content\n",
    "    return {\"messages\": response}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 4 Edges </h2>\n",
    "<p> Since we do not have any optional paths that the graph can take, we do not need to specify any conditional edges. </p>\n",
    "<br>\n",
    "<h2> 5 Compile workflow </h2>\n",
    "<p> In the code cell below you have two tasks: \n",
    "    <ol>\n",
    "        <li> Give a name to a node and define which function it shall utilize.</li>\n",
    "        <li> Specify the start and end nodes for two edges.</li>\n",
    "    </ol> \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(State)\n",
    "memory = MemorySaver()\n",
    "\n",
    "workflow.add_node(\"refine\", refine_node)\n",
    "# Fill in the blanks\n",
    "workflow.add_node(None, None)\n",
    "\n",
    "workflow.add_edge(START, \"refine\")\n",
    "# Fill in the blanks\n",
    "workflow.add_edge(None,None)\n",
    "workflow.add_edge(None, END)\n",
    "\n",
    "mygraph = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Get an visual representation of the graph you just compiled. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    display(Image(mygraph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 6  Start chatting </h2>\n",
    "<p> Run the cell below without editing, and start chatting with your agentic AI-application </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_graph_updates(user_input: str):\n",
    "    for event in mygraph.stream({\"messages\": [(\"user\", user_input)]},\n",
    "                                {\"configurable\": {\"thread_id\": \"123abc\"}}):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value)\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        print(user_input)\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        # fallback if input() is not available\n",
    "        user_input = \"----Something wong here------\"    \n",
    "        print(\"User: \" + user_input)\n",
    "        stream_graph_updates(user_input)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Finale </h2>\n",
    "<p> Congratulations, you have just completed this notebook \"tutorial\"!</p>\n",
    "<br>\n",
    "<p> You are now free to either continue building functionality on this graph, or start from scratch and build your own one. There are many possibilities with Langgraph </p>\n",
    "<br>\n",
    "<p>\n",
    "    <b>Recommened reading/tutorials:</b>\n",
    "        <ul>\n",
    "            <li><a href=\"https://python.langchain.com/docs/introduction/\"> Langchain</a>, building chatbots. </li>\n",
    "            <li><a href=\"https://langchain-ai.github.io/langgraph/tutorials/introduction/\">Langgraph</a>, building agentic systems </li>\n",
    "            <li><a href=\"https://docs.smith.langchain.com/\">Langsmith</a>, monitor graph actions. </li>\n",
    "        </ul>\n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvLSDC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
